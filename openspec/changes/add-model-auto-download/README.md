# Model Auto-Download: Implementation Package

## ğŸ“‹ Quick Overview

This directory contains the **complete specification, design, and implementation plan** for the Model Auto-Download feature across all 3 phases.

The feature enables users to automatically download and verify video analysis models with a single CLI flag: `python -m video_censor --download-models`

---

## ğŸ“ Files in This Package

### Core Proposal Documents

| File | Purpose | Read When |
|------|---------|-----------|
| **proposal.md** | Executive summary: why, what, impact | First (2 min read) |
| **design.md** | Architecture, decisions, risks, migration plan | Before coding (5 min read) |
| **tasks.md** | Implementation checklist (~60 items) | While implementing |
| **specs/project-foundation/spec.md** | 13 detailed requirements with scenarios | Reference while building |

### Implementation Coordination

| File | Purpose | Read When |
|------|---------|-----------|
| **PARALLELIZATION.md** | 7 independent workstreams, timeline, merge strategy | ğŸ“Œ **Before starting** (critical path planning) |
| **API_CONTRACTS.md** | Exact interfaces between streams (code-level) | ğŸ“Œ **Before coding** (prevents merge conflicts) |
| **IMPLEMENTATION_KICKOFF.md** | Day-1 checklist, per-subagent workflow, troubleshooting | **Day 1** (kickoff guide) |
| **README.md** | This file â€” navigation guide | Right now |

---

## ğŸ¯ Three-Phase Architecture

### Phase 1: Foundation (Days 1-4)
CLI flag + Model Manager + configuration schema

**Streams A, B, C, D (partial)**
- `--download-models` flag
- Atomic downloads with checksum validation
- Progress reporting (tqdm)
- Retry logic with exponential backoff
- Disk space pre-checks
- Hugging Face as default source

**Exit Criteria**: `python -m video_censor --download-models` downloads models successfully

### Phase 2: Pipeline Integration (Days 5-6)
Auto-invoke downloads during analysis pipeline init

**Streams E, D (partial)**
- Detect missing models at pipeline startup
- Auto-invoke downloads if flag set
- Seamless resume after download (no restart needed)
- Single unified workflow for users

**Exit Criteria**: Missing models trigger auto-download; analysis continues transparently

### Phase 3: Auto-Discovery (Days 7-9)
Hugging Face registry integration + model caching

**Streams F, D (partial)**
- Query Hugging Face for available models
- Cache metadata (24h TTL)
- Model version pinning + fallback
- Deprecation warnings

**Exit Criteria**: Auto-discovery populates cache; suggestions for deprecated models

### Documentation (Parallel, Days 2-10)
User guides, API docs, troubleshooting

**Stream G**
- README with examples
- YAML configuration guide
- Troubleshooting section
- Quick-start guide

---

## ğŸš€ Getting Started

### For Project Managers / Integration Owners

1. **Understand scope**: Read `proposal.md` (2 min)
2. **Review timeline**: Read `PARALLELIZATION.md` â†’ Estimated Timeline table (2 min)
3. **Plan approval gates**: Reference `PARALLELIZATION.md` â†’ Merge Strategy (3 min)
4. **Monitor progress**: Use `tasks.md` as checklist; mark items complete as streams deliver

### For Subagents

1. **Day 1 Kickoff**: Read `IMPLEMENTATION_KICKOFF.md` (5 min)
2. **Understand your stream**: Read `PARALLELIZATION.md` â†’ [Stream X] section (3 min)
3. **Know the contracts**: Read `API_CONTRACTS.md` (10 min) â† **Critical before coding**
4. **Check your tasks**: Reference `tasks.md` for your stream's checklist
5. **Start implementing**: Follow tasks in order; validate with tests

### For Code Reviewers

1. **Know the spec**: Read `specs/project-foundation/spec.md` (scenarios section)
2. **Know the API contracts**: Reference `API_CONTRACTS.md` for expected interfaces
3. **Check the checklist**: Verify PR claims cover all relevant tasks.md items
4. **Validate tests**: >80% coverage, all unit + integration tests pass

---

## ğŸ“Š Parallelization Summary

**7 independent workstreams** working simultaneously on different modules:

```
Stream A: Config Schema       (1-2 days) â”€â†’ blocks B
Stream B: Model Manager       (2-3 days) â”€â”¬â”€â†’ blocks C, E
Stream C: CLI Integration     (1-2 days) â”€â”¤â”€â†’ blocks E
Stream D: Testing             (2-3 days) â† feeds from A-G (parallel)
Stream E: Pipeline Integration(1-2 days) â† blocks F
Stream F: HF Registry         (2-3 days) â† feeds E
Stream G: Documentation       (1-2 days) â† parallel, no blocks

Critical Path: A â†’ B â†’ C â†’ E â†’ F (9-10 days)
With Parallelization: ~4-5 days actual calendar time
```

**Key**: Streams 1-7 don't wait for each other (except where noted).

---

## ğŸ“‹ Decision Log

**Answers to open questions from design.md:**

| Question | Answer | Rationale |
|----------|--------|-----------|
| Model sources? | Hugging Face (primary) + configurable fallback | Well-maintained registry; flexibility for custom sources |
| Checksum algorithm? | SHA256 + support Hugging Face alternatives | Industry standard; extensible for future sources |
| Timeout strategy? | Fixed defaults (300s, 3 retries, 2/4/8s backoff) | Reasonable for typical models; YAML extension available post-MVP |
| Cache directory? | Platform defaults via `platformdirs` library | Cross-platform consistency; respects OS conventions |
| Phases in this change? | All 3 (CLI, Pipeline, Auto-Discovery) | Cohesive feature; users get full benefit immediately |

---

## âœ… Success Criteria

When all 3 phases complete:

- âœ… Users run `python -m video_censor --download-models` once
- âœ… Models auto-download to platform-appropriate cache
- âœ… Progress bar shows speed/ETA/completion
- âœ… Corrupted models re-download automatically
- âœ… Pipeline auto-invokes if flag set
- âœ… Analysis resumes without restart
- âœ… Hugging Face models auto-discovered
- âœ… Deprecated models trigger helpful suggestions
- âœ… >80% test coverage
- âœ… No regressions to existing functionality

---

## ğŸ“– Reading Order

### For Different Roles

**Project Manager / Owner**
1. proposal.md (why + what)
2. PARALLELIZATION.md (timeline, streams, gates)
3. tasks.md (checklist to track)

**Subagent (Developer)**
1. IMPLEMENTATION_KICKOFF.md (start here!)
2. PARALLELIZATION.md (your stream)
3. API_CONTRACTS.md (before coding)
4. tasks.md (your tasks)
5. design.md (reference for decisions)

**QA / Code Reviewer**
1. specs/project-foundation/spec.md (requirements)
2. API_CONTRACTS.md (interfaces to verify)
3. tasks.md (coverage areas)
4. design.md (risk mitigation strategies)

**Future Maintainer**
1. design.md (why things are this way)
2. API_CONTRACTS.md (module boundaries)
3. specs/project-foundation/spec.md (behavior spec)
4. source code (implementation details)

---

## ğŸ”— Integration Points

| Component | Location | Owner | Notes |
|-----------|----------|-------|-------|
| Config schema | `video_censor_personal/config.py` | Stream A | Must include `.models` field |
| ModelManager | `video_censor_personal/model_manager.py` | Stream B | Core download logic |
| CLI flag | `video_censor_personal/__main__.py` | Stream C | Calls `pipeline.verify_models()` |
| Pipeline integration | `video_censor_personal/analysis_pipeline.py` | Stream E | Calls `ModelManager.verify_models()` |
| HF Registry | `video_censor_personal/huggingface_registry.py` | Stream F | Optional; used by Pipeline for warnings |
| Tests | `tests/unit/` + `tests/integration/` | Stream D | Validates all phases |
| Documentation | `README.md`, `.md` files in docs/ | Stream G | User guides + API docs |

---

## ğŸš¨ Critical Blockers

**These must be respected:**

1. **Stream A must merge before Stream B** production code (B can use mocks initially)
2. **Streams B + C must complete Phase 1** before Stream E begins
3. **Stream E must complete Phase 2** before Stream F begins
4. **All tests must pass** before each phase exit gate
5. **No breaking API changes** to existing modules (backward compatible)

**If blocked, escalate immediately to integration owner.**

---

## ğŸ“ Communication & Review

### Standup Format
Post daily by EOD in shared channel:
```
Stream X (Your Name)
âœ… Completed: Tasks X.1, X.2
ğŸš§ In Progress: Task X.3 (ETA tomorrow)
ğŸ”´ Blockers: [if any]
â¡ï¸ Next: Task X.4
```

### PR Review Gates
- 1 approval for documentation/testing
- 2 approvals for core API changes (B, E, F)
- Reference completed tasks.md items
- >80% code coverage required

### Integration Syncs
- Weekly or at phase exit gates
- Verify no merge conflicts
- Run full test suite
- Unlock next phase

---

## ğŸ“š Appendix: Document Map

```
add-model-auto-download/
â”œâ”€â”€ README.md â† You are here
â”œâ”€â”€ proposal.md
â”‚   â””â”€â”€ Why: Reduce setup friction
â”‚   â””â”€â”€ What: 3 phases of model management
â”‚   â””â”€â”€ Impact: Affected specs/code
â”œâ”€â”€ design.md
â”‚   â””â”€â”€ Context & constraints
â”‚   â””â”€â”€ Architecture decisions (5)
â”‚   â””â”€â”€ Risk mitigation
â”‚   â””â”€â”€ Implementation plan (all 3 phases)
â”œâ”€â”€ tasks.md
â”‚   â””â”€â”€ 60+ items across 13 sections
â”‚   â””â”€â”€ Organized by phase + stream
â”‚   â””â”€â”€ Dependencies noted
â”œâ”€â”€ PARALLELIZATION.md â† **Critical for coordination**
â”‚   â””â”€â”€ 7 workstreams defined
â”‚   â””â”€â”€ Dependencies, timeline, critical path
â”‚   â””â”€â”€ Merge strategy & gates
â”‚   â””â”€â”€ 4-5 day actual duration
â”œâ”€â”€ API_CONTRACTS.md â† **Critical for coding**
â”‚   â””â”€â”€ Exact interface contracts
â”‚   â””â”€â”€ Code signatures, docstring formats
â”‚   â””â”€â”€ Integration sequences
â”‚   â””â”€â”€ Approval gates per stream
â”œâ”€â”€ IMPLEMENTATION_KICKOFF.md â† **Day 1 for subagents**
â”‚   â””â”€â”€ Quick start checklist
â”‚   â””â”€â”€ Worktree setup commands
â”‚   â””â”€â”€ Per-stream workflows
â”‚   â””â”€â”€ Testing strategy
â”‚   â””â”€â”€ Error handling
â”‚   â””â”€â”€ Code quality standards
â”‚   â””â”€â”€ Troubleshooting
â””â”€â”€ specs/
    â””â”€â”€ project-foundation/
        â””â”€â”€ spec.md
            â””â”€â”€ 13 ADDED requirements
            â””â”€â”€ 30+ scenarios
            â””â”€â”€ Phase labels (P1, P2, P3)
```

---

## ğŸ“ How to Use This Package

### Scenario: "I'm the project manager, what do I need to know?"
â†’ Read: proposal.md (2 min) + PARALLELIZATION.md timeline table (2 min)  
â†’ Use: tasks.md as your tracking checklist

### Scenario: "I'm assigned Stream B, where do I start?"
â†’ Read: IMPLEMENTATION_KICKOFF.md (5 min) + PARALLELIZATION.md (Stream B section)  
â†’ Then: API_CONTRACTS.md â†’ ModelManager section  
â†’ Finally: tasks.md â†’ Section 2 (your tasks)  
â†’ Code: Implement using API_CONTRACTS.md as interface spec

### Scenario: "I'm reviewing a PR from Stream C"
â†’ Check: API_CONTRACTS.md â†’ Stream A + B â†’ Stream C section  
â†’ Verify: PR implements all required methods with exact signatures  
â†’ Test: Run `pytest tests/integration/test_download_flow.py -v`  
â†’ Approve: If tests pass, interfaces match, >80% coverage

### Scenario: "We're blocked on Stream B, what do we do?"
â†’ Check: PARALLELIZATION.md â†’ Stream B section â†’ dependencies  
â†’ Escalate: If dependency (Stream A) not merging, contact Stream A owner  
â†’ Workaround: If unblockable, request early review/approval to merge partial

---

## âœ¨ Final Checklist Before Implementation Starts

- [ ] All team members have read IMPLEMENTATION_KICKOFF.md
- [ ] Worktrees created (`git worktree add ...` commands)
- [ ] API_CONTRACTS.md reviewed by all developers
- [ ] Design decisions understood (design.md finalized section)
- [ ] Phase 1 exit criteria defined and agreed
- [ ] Code review process established (PR template, approval process)
- [ ] Test framework setup (tqdm for progress, mock HTTP server ready)
- [ ] Dependency versions agreed (tqdm, platformdirs, requests, etc.)
- [ ] CI/CD configured for >80% coverage requirement
- [ ] Standup schedule set (async daily or sync 3x/week)
- [ ] Integration owner assigned and available

**Ready to build! ğŸš€**
