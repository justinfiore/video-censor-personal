# Video Censor Personal - Example Configuration
# Copy this file to video-censor.yaml and modify settings as needed

version: 1.0

# Detection settings
detections:
  nudity:
    enabled: true
    sensitivity: 0.7          # 0.0 (permissive) to 1.0 (strict)
    model: "local"            # "local" or fallback service name
  
  profanity:
    enabled: true
    sensitivity: 0.8
    model: "local"
  
  violence:
    enabled: true
    sensitivity: 0.6
    model: "local"
  
  sexual_themes:
    enabled: true
    sensitivity: 0.75
    model: "local"
  
  # Custom detection categories (future expansion)
  logos:
    enabled: false
    sensitivity: 0.5
    model: "local"
  
  spoilers:
    enabled: false
    sensitivity: 0.6
    model: "local"

# Detector configuration (experimental)
# These settings configure the detection framework with specific detector implementations.
# Currently supported: "llava" (LLaVA vision-language model)
detectors:
  - type: "llava"                             # Detector implementation type
    name: "llava-primary"                     # Instance name
    model_name: "liuhaotian/llava-v1.5-7b"   # Model variant (7b or 13b)
    model_path: null                          # Optional custom cache path (null = use HF default)
    prompt_file: "./prompts/llava-detector.txt"  # Path to prompt template
    # GPU/Device Configuration:
    # - null or omit: Auto-detect (CUDA → MPS → CPU)
    # - "cuda": Force NVIDIA CUDA GPU (errors if unavailable)
    # - "mps": Force Apple Silicon Metal Performance Shaders
    # - "cpu": Force CPU (slower but always available)
    device: null
    categories:                                # Categories this detector analyzes
      - "Nudity"
      - "Profanity"
      - "Violence"
      - "Sexual Theme"

# Video processing settings
processing:
  # Frame sampling strategy
  frame_sampling:
    strategy: "uniform"       # Options: "uniform", "scene_based", "all"
    sample_rate: 1.0          # seconds between frame analysis (1.0 = every second)
  
  # Segment merging and aggregation
  segment_merge:
    enabled: true
    merge_threshold: 2.0      # merge segments within N seconds
  
  # Parallel processing
  max_workers: 4              # number of parallel workers

# Output settings
output:
  format: "json"              # Only "json" is currently supported
  include_confidence: true    # include confidence scores in results
  pretty_print: true          # human-readable JSON formatting

# Video metadata output configuration
# Skip chapters allow users to jump between flagged segments in media players
video:
  metadata_output:
    skip_chapters:
      enabled: false          # Set to true to write detection segments as chapter markers
                               # Supports both MKV and MP4 formats with native chapter atoms
                               # Use --output-video output.mkv or --output-video output.mp4
                               # Both formats provide reliable cross-platform chapter support

# Model download and caching configuration (optional)
# Automatically download and verify models with --download-models CLI flag
models:
  # Custom cache directory (optional; defaults to platform-appropriate location)
  # On Linux/macOS: ~/.cache/video-censor/models
  # On Windows: %APPDATA%\video-censor\models
  cache_dir: null
  
  # Model sources: downloadable models with checksums
  sources:
    # LLaVA 7B vision-language model (Hugging Face)
    - name: "llava-7b"
      url: "https://huggingface.co/liuhaotian/llava-v1.5-7b/resolve/main/model-00001-of-00004.safetensors"
      checksum: "1a2b3c4d5e6f7a8b9c0d1e2f3a4b5c6d7e8f9a0b1c2d3e4f5a6b7c8d9e0f1a2b"
      size_bytes: 3825156096
      algorithm: "sha256"
      optional: false
    
    # Speech profanity detector (Hugging Face)
    - name: "profanity-detector"
      url: "https://huggingface.co/michellejieli/BERT_distilbert_uncased_L-4_H-256_A-4/resolve/main/pytorch_model.bin"
      checksum: "2f3a4b5c6d7e8f9a0b1c2d3e4f5a6b7c8d9e0f1a2b3c4d5e6f7a8b9c0d1e2f"
      size_bytes: 268435456
      algorithm: "sha256"
      optional: false
  
  # Pre-configured auto-download (future feature; currently use --download-models flag)
  auto_download: false

# Legacy model configuration (for backward compatibility with local setup)
model_config:
  local:
    # Local model settings (optional - uses transformers defaults)
    vision_model: "liuhaotian/llava-v1.5-7b"
    cache_dir: "./models"
  
  third_party:
    # Third-party service fallback
    enabled_fallback: false
    providers:
      - name: "example_api"
        enabled: false
        # API credentials loaded from environment variables
