# Video Censor Personal - Example Configuration
# Copy this file to video-censor.yaml and modify settings as needed

version: 1.0

# Detection settings
detections:
  nudity:
    enabled: true
    sensitivity: 0.7          # 0.0 (permissive) to 1.0 (strict)
    model: "local"            # "local" or fallback service name
  
  profanity:
    enabled: true
    sensitivity: 0.8
    model: "local"
  
  violence:
    enabled: true
    sensitivity: 0.6
    model: "local"
  
  sexual_themes:
    enabled: true
    sensitivity: 0.75
    model: "local"
  
  # Custom detection categories (future expansion)
  logos:
    enabled: false
    sensitivity: 0.5
    model: "local"
  
  spoilers:
    enabled: false
    sensitivity: 0.6
    model: "local"

# Detector configuration (experimental)
# These settings configure the detection framework with specific detector implementations.
# Currently supported: "llava" (LLaVA vision-language model)
detectors:
  - type: "llava"                             # Detector implementation type
    name: "llava-primary"                     # Instance name
    model_name: "liuhaotian/llava-v1.5-7b"   # Model variant (7b or 13b)
    model_path: null                          # Optional custom cache path (null = use HF default)
    prompt_file: "./prompts/llava-detector.txt"  # Path to prompt template
    categories:                                # Categories this detector analyzes
      - "Nudity"
      - "Profanity"
      - "Violence"
      - "Sexual Theme"

# Video processing settings
processing:
  # Frame sampling strategy
  frame_sampling:
    strategy: "uniform"       # Options: "uniform", "scene_based", "all"
    sample_rate: 1.0          # seconds between frame analysis (1.0 = every second)
  
  # Segment merging and aggregation
  segment_merge:
    enabled: true
    merge_threshold: 2.0      # merge segments within N seconds
  
  # Parallel processing
  max_workers: 4              # number of parallel workers

# Output settings
output:
  format: "json"              # Only "json" is currently supported
  include_confidence: true    # include confidence scores in results
  pretty_print: true          # human-readable JSON formatting

# Model configuration
models:
  local:
    # Local model settings (optional - uses transformers defaults)
    vision_model: "liuhaotian/llava-v1.5-7b"
    cache_dir: "./models"
  
  third_party:
    # Third-party service fallback
    enabled_fallback: false
    providers:
      - name: "example_api"
        enabled: false
        # API credentials loaded from environment variables
